{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9236aea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f492696e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Atharva\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List, Tuple\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from datasets import load_dataset, concatenate_datasets, Dataset, DatasetDict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a159d4",
   "metadata": {},
   "source": [
    "Import Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "684bf2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1 = load_dataset(\"ccdv/govreport-summarization\")\n",
    "ds2 = load_dataset(\"FiscalNote/billsum\")\n",
    "\n",
    "# GovReport splits (report, summary)\n",
    "gov_train = ds1[\"train\"].rename_columns({\"report\": \"text\"})\n",
    "gov_val   = ds1[\"validation\"].rename_columns({\"report\": \"text\"})\n",
    "gov_test  = ds1[\"test\"].rename_columns({\"report\": \"text\"})\n",
    "\n",
    "# BillSum splits (text, summary, title)\n",
    "bill_train = ds2[\"train\"]\n",
    "bill_test  = ds2[\"test\"]\n",
    "bill_ca_test = ds2[\"ca_test\"]  # treat as out of domain test for model generalisation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83f5ed8",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03f7fd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove boilerplate for text\n",
    "\n",
    "header_irrelevant = [\n",
    "    r\"^Page\\s+\\d+(\\s+of\\s+\\d+)?\\s*$\", # pages e.g. Page 3\n",
    "    r\"^\\d+\\s*$\", # numbers e.g. 13\n",
    "    r\"^–\\s*\\d+\\s*–$\", # e.g. - 12 -\n",
    "    r\"^\\s*U\\.S\\. Government Accountability Office.*$\", # common report headers\n",
    "    r\"^\\s*Congressional Research Service.*$\",\n",
    "    r\"^\\s*Congressional Budget Office.*$\",\n",
    "    r\"^\\s*GAO-\\d{2}-\\d+\\s*$\", # report ids\n",
    "    r\"^\\s*For Official Use Only\\s*$\",\n",
    "    r\"^\\s*This report was prepared by.*$\",\n",
    "]\n",
    "\n",
    "toc_irrelevant = [\n",
    "    r\"^\\s*Table of Contents\\s*$\",\n",
    "    r\"\\.{2,}\\s*\\d+\\s*$\", # dotted lines with page numbers\n",
    "]\n",
    "\n",
    "# remove excessive whitespaces, line breaks\n",
    "def remove_whitespaces(text):\n",
    "    text = re.sub(r'\\r\\n', '\\n', text)\n",
    "    text = re.sub(r'[ \\t]+', ' ', text) # multiple spaces into single space\n",
    "    text = re.sub(r'\\n{3,}', '\\n\\n', text) # 3+ consecutive newlines into two to keep paragraph breaks\n",
    "    return text.strip() # drop leading/trailing whitespaces\n",
    "\n",
    "def remove_boilerplate(text):\n",
    "    if not text or not isinstance(text, str):\n",
    "        return text\n",
    "    \n",
    "    # standardize unicode/punctuation for tokenizer consistency\n",
    "    text = unicodedata.normalize(\"NFKC\", text)\n",
    "\n",
    "    lines = text.splitlines()\n",
    "    cleaned = []\n",
    "\n",
    "    inside_toc = False\n",
    "    for line in lines:\n",
    "        line_stripped = line.strip()\n",
    "\n",
    "        if any(re.match(i, line_stripped) for i in header_irrelevant):\n",
    "            continue\n",
    "\n",
    "        if any(re.match(i, line_stripped) for i in toc_irrelevant):\n",
    "            inside_toc = True\n",
    "            continue\n",
    "\n",
    "        if inside_toc:\n",
    "            # skip TOC lines till normal paragraph appears\n",
    "            if re.search(r\"\\.{2,}\\s*\\d+\\s*$\", line_stripped):\n",
    "                continue\n",
    "            inside_toc = False\n",
    "\n",
    "        cleaned.append(line)\n",
    "\n",
    "    cleaned_text = \"\\n\".join(cleaned)\n",
    "    cleaned_text = remove_whitespaces(cleaned_text)\n",
    "    # remove rule lines ------ / =====\n",
    "    cleaned_text = re.sub(r\"(?:^|\\n)[\\-=]{4,}(?:\\n|$)\", \"\\n\", cleaned_text)\n",
    "    # remove HTML tags\n",
    "    tags = re.compile(r\"<[^>]+>|&[a-zA-Z]+;\")\n",
    "    if isinstance(cleaned_text, str) and tags.search(cleaned_text):\n",
    "        cleaned_text = BeautifulSoup(cleaned_text, \"html.parser\").get_text(separator=\" \")\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "gov_train = gov_train.map(lambda ex: {\"clean_text\": remove_boilerplate(ex[\"text\"])})\n",
    "gov_val = gov_val.map(lambda ex: {\"clean_text\": remove_boilerplate(ex[\"text\"])})\n",
    "gov_test = gov_test.map(lambda ex: {\"clean_text\": remove_boilerplate(ex[\"text\"])})\n",
    "\n",
    "bill_train = bill_train.map(lambda ex: {\"clean_text\": remove_boilerplate(ex[\"text\"])})\n",
    "bill_test = bill_test.map(lambda ex: {\"clean_text\": remove_boilerplate(ex[\"text\"])})\n",
    "bill_ca_test = bill_ca_test.map(lambda ex: {\"clean_text\": remove_boilerplate(ex[\"text\"])})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d78082c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove minimal whitespaces for summary\n",
    "def clean_summary(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "gov_train = gov_train.map(lambda ex: {\"clean_summary\": clean_summary(ex[\"summary\"])})\n",
    "gov_val   = gov_val.map(lambda ex: {\"clean_summary\": clean_summary(ex[\"summary\"])})\n",
    "gov_test  = gov_test.map(lambda ex: {\"clean_summary\": clean_summary(ex[\"summary\"])})\n",
    "\n",
    "bill_train = bill_train.map(lambda ex: {\"clean_summary\": clean_summary(ex[\"summary\"])})\n",
    "bill_test  = bill_test.map(lambda ex: {\"clean_summary\": clean_summary(ex[\"summary\"])})\n",
    "bill_ca_test   = bill_ca_test.map(lambda ex: {\"clean_summary\": clean_summary(ex[\"summary\"])})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705980df",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e4fa15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import re\n",
    "\n",
    "# Download punkt if not already available\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "\n",
    "def safe_sent_split(text):\n",
    "    \"\"\"\n",
    "    Safely split text into sentences with heading merging\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        sents = sent_tokenize(text)\n",
    "        \n",
    "        # Merge headings with next sentence\n",
    "        output = []\n",
    "        heading = None\n",
    "        \n",
    "        for s in sents:\n",
    "            s = s.strip()\n",
    "            if not s:\n",
    "                continue\n",
    "            \n",
    "            # Check if this looks like a heading\n",
    "            if (heading is None and \n",
    "                len(s) <= 25 and \n",
    "                (s.endswith(\":\") or re.match(r\"^[A-Z][A-Za-z0-9 \\-]{0,20}:?$\", s))):\n",
    "                heading = s\n",
    "                continue\n",
    "            \n",
    "            # If we have a heading, merge it with current sentence\n",
    "            if heading is not None:\n",
    "                output.append(f\"{heading} {s}\".strip())\n",
    "                heading = None\n",
    "            else:\n",
    "                output.append(s)\n",
    "        \n",
    "        # Add any remaining heading\n",
    "        if heading is not None:\n",
    "            output.append(heading)\n",
    "            \n",
    "        return output\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in sentence splitting: {e}\")\n",
    "        # Fallback: simple split by periods\n",
    "        return [s.strip() for s in text.split('.') if s.strip()]\n",
    "\n",
    "# Alternative simpler approach without heading merging\n",
    "def simple_sent_split(text):\n",
    "    \"\"\"Simple sentence splitting without heading logic\"\"\"\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        return [s.strip() for s in sent_tokenize(text) if s.strip()]\n",
    "    except:\n",
    "        return [s.strip() for s in text.split('.') if s.strip()]\n",
    "\n",
    "# Apply to datasets using the simpler approach\n",
    "gov_train = gov_train.map(lambda ex: {\"sentences\": simple_sent_split(ex[\"clean_text\"])}, batched=False)\n",
    "gov_val = gov_val.map(lambda ex: {\"sentences\": simple_sent_split(ex[\"clean_text\"])}, batched=False)\n",
    "gov_test = gov_test.map(lambda ex: {\"sentences\": simple_sent_split(ex[\"clean_text\"])}, batched=False)\n",
    "\n",
    "bill_train = bill_train.map(lambda ex: {\"sentences\": simple_sent_split(ex[\"clean_text\"])}, batched=False)\n",
    "bill_test = bill_test.map(lambda ex: {\"sentences\": simple_sent_split(ex[\"clean_text\"])}, batched=False)\n",
    "bill_ca_test = bill_ca_test.map(lambda ex: {\"sentences\": simple_sent_split(ex[\"clean_text\"])}, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8535f74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32f20025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset splits for modeling\n",
    "split = bill_test.train_test_split(test_size=0.5, seed=42)\n",
    "bill_val = split[\"train\"]\n",
    "bill_test = split[\"test\"]\n",
    "\n",
    "# Combined\n",
    "comb_train = concatenate_datasets([gov_train, bill_train.select_columns(['text', 'summary', 'clean_text', 'clean_summary', 'sentences'])])\n",
    "comb_val = concatenate_datasets([gov_val, bill_val.select_columns(['text', 'summary', 'clean_text', 'clean_summary', 'sentences'])])\n",
    "comb_test = concatenate_datasets([gov_test, bill_test.select_columns(['text', 'summary', 'clean_text', 'clean_summary', 'sentences'])])\n",
    "# add source column\n",
    "comb_train = comb_train.add_column(\"source\",[\"govreport\"] * len(gov_train) + [\"billsum\"] * len(bill_train))\n",
    "comb_val = comb_val.add_column(\"source\",[\"govreport\"] * len(gov_val) + [\"billsum\"] * len(bill_val))\n",
    "comb_test = comb_test.add_column(\"source\",[\"govreport\"] * len(gov_test) + [\"billsum\"] * len(bill_test))\n",
    "# shuffle to avoid bias\n",
    "comb_train = comb_train.shuffle(seed=42)\n",
    "comb_val = comb_val.shuffle(seed=42)\n",
    "comb_test = comb_test.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b9497f",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ae2fca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7995fd5b",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50332fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84d8e7ba",
   "metadata": {},
   "source": [
    "Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a46000b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Extractive ROUGE Scores: {'rouge1': 0.2692639621339274, 'rouge2': 0.12041119417612786, 'rougeL': 0.175222460579046, 'rougeLsum': 0.19015080435007944}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Extractive Baseline: TF-IDF Cosine Similarity\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from datasets import Dataset\n",
    "\n",
    "def extractive_summary(sentences: list, top_n: int = 3) -> str:\n",
    "    \"\"\"Return extractive summary using sentence similarity\"\"\"\n",
    "    if not sentences:\n",
    "        return \"\"\n",
    "    if len(sentences) <= top_n:\n",
    "        return \" \".join(sentences)\n",
    "    \n",
    "    # TF-IDF vectorization\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    X = vectorizer.fit_transform(sentences)\n",
    "    \n",
    "    # Cosine similarity matrix\n",
    "    sim_matrix = cosine_similarity(X, X)\n",
    "    \n",
    "    # Sentence scores: sum of similarities\n",
    "    scores = sim_matrix.sum(axis=1)\n",
    "    \n",
    "    # Pick top_n sentences\n",
    "    top_indices = np.argsort(scores)[-top_n:][::-1]\n",
    "    \n",
    "    # Return sentences in original order\n",
    "    summary = [sentences[i] for i in sorted(top_indices)]\n",
    "    return \" \".join(summary)\n",
    "\n",
    "# Add extractive summaries to dataset\n",
    "def add_extractive_predictions(dataset: Dataset, top_n: int = 3) -> Dataset:\n",
    "    summaries = [extractive_summary(ex[\"sentences\"], top_n=top_n) for ex in dataset]\n",
    "    return dataset.add_column(\"extractive_summary\", summaries)\n",
    "\n",
    "# Example: test on small subset\n",
    "comb_val_small = comb_val.select(range(100))  # first 100 for quick run\n",
    "comb_val_small = add_extractive_predictions(comb_val_small, top_n=3)\n",
    "\n",
    "# ROUGE Evaluation\n",
    "import evaluate\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "preds = comb_val_small[\"extractive_summary\"]\n",
    "refs  = comb_val_small[\"clean_summary\"]\n",
    "\n",
    "results = rouge.compute(predictions=preds, references=refs)\n",
    "print(\"Initial Extractive ROUGE Scores:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113ced85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import PegasusTokenizer, PegasusForConditionalGeneration, Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "#Testing Fine Tuning on easy model - still breaks kernel need GPU\n",
    "demo_train = comb_train.select(range(500))  \n",
    "demo_val   = comb_val.select(range(100))    \n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_name = \"sshleifer/distilbart-cnn-12-6\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "max_input_length = 128\n",
    "max_target_length = 32 \n",
    "\n",
    "def preprocess(batch):\n",
    "    inputs = tokenizer(batch[\"clean_text\"], truncation=True, padding=\"max_length\", max_length=max_input_length)\n",
    "    targets = tokenizer(batch[\"clean_summary\"], truncation=True, padding=\"max_length\", max_length=max_target_length)\n",
    "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "    return inputs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
